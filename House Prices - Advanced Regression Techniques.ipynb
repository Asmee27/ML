{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "K2nDuORZYvjM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Sph4oat2Y9V3"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "y = np.log1p(train[\"SalePrice\"])   # log(1 + SalePrice)\n",
        "train.drop(\"SalePrice\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1271qdK4Y_SU"
      },
      "outputs": [],
      "source": [
        "all_data = pd.concat([train, test], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PTc6B0D0ZBSJ"
      },
      "outputs": [],
      "source": [
        "# Age of house\n",
        "all_data[\"HouseAge\"] = all_data[\"YrSold\"] - all_data[\"YearBuilt\"]\n",
        "all_data[\"RemodAge\"] = all_data[\"YrSold\"] - all_data[\"YearRemodAdd\"]\n",
        "\n",
        "# Save test_ids before dropping 'Id' from all_data\n",
        "# Use original 'test' DataFrame for robust extraction of test_ids\n",
        "test_ids = test[\"Id\"]\n",
        "\n",
        "# Drop Id from all_data\n",
        "# Use errors='ignore' for robustness against multiple cell executions\n",
        "all_data.drop(\"Id\", axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "# Split all_data back into train and test after feature engineering\n",
        "# Use len(y) to get the original length of the training data reliably\n",
        "original_train_len = len(y)\n",
        "train = all_data.iloc[:original_train_len, :] # Redefine train with engineered features\n",
        "test = all_data.iloc[original_train_len:, :] # Redefine test with engineered features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "bzb3VLGKZDPg"
      },
      "outputs": [],
      "source": [
        "num_features = train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "cat_features = train.select_dtypes(include=[\"object\"]).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "UZr_j1quZFIj"
      },
      "outputs": [],
      "source": [
        "num_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\",\n",
        "     __import__(\"sklearn\").preprocessing.OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_features),\n",
        "    (\"cat\", cat_pipeline, cat_features)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "cFI5vJqIZG_C"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "HurAjm8JZJS8"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    (\"prep\", preprocessor),\n",
        "    (\"model\", model)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7r9P17RZLX_"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmse = np.sqrt(-cross_val_score(\n",
        "    pipeline, train, y,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=kf\n",
        "))\n",
        "\n",
        "print(\"CV RMSE:\", rmse.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__Gc139rZNQS"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(train, y)\n",
        "\n",
        "preds = pipeline.predict(test)\n",
        "preds = np.expm1(preds)   # reverse log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdPejm0nZPMw"
      },
      "outputs": [],
      "source": [
        "if 'preds' not in locals() and 'preds' not in globals():\n",
        "    raise NameError(\"The 'preds' variable is not defined. Please ensure the model fitting and prediction cell (__Gc139rZNQS) has been executed before running this cell.\")\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"SalePrice\": preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50af9ee0"
      },
      "source": [
        "# Task\n",
        "Generate advanced features (e.g., polynomial, interaction terms, or domain-specific aggregations) from the existing features in the `all_data` DataFrame. Ensure to update the `num_features` and `cat_features` lists to reflect these new features, and then re-evaluate the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bbf4215"
      },
      "outputs": [],
      "source": [
        "all_data[\"TotalSF\"] = all_data[\"GrLivArea\"] + all_data[\"TotalBsmtSF\"]\n",
        "all_data[\"TotalBath\"] = (\n",
        "    all_data[\"FullBath\"]\n",
        "    + 0.5 * all_data[\"HalfBath\"]\n",
        "    + all_data[\"BsmtFullBath\"]\n",
        "    + 0.5 * all_data[\"BsmtHalfBath\"]\n",
        ")\n",
        "all_data[\"OverallQual_GrLivArea\"] = all_data[\"OverallQual\"] * all_data[\"GrLivArea\"]\n",
        "all_data[\"HasPool\"] = (all_data[\"PoolArea\"] > 0).astype(int)\n",
        "\n",
        "# Re-split all_data back into train and test after feature engineering\n",
        "train = all_data.iloc[:original_train_len, :]\n",
        "test = all_data.iloc[original_train_len:, :]\n",
        "\n",
        "# Update feature lists\n",
        "num_features = train.select_dtypes(include=np.number).columns\n",
        "cat_features = train.select_dtypes(include=object).columns\n",
        "\n",
        "print(\"Advanced features created and train/test DataFrames updated.\")\n",
        "print(f\"New num_features count: {len(num_features)}\")\n",
        "print(f\"New cat_features count: {len(cat_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aa29267"
      },
      "source": [
        "**Reasoning**:\n",
        "With the `num_features` and `cat_features` lists now updated to include the newly engineered features, I need to redefine the `preprocessor` to incorporate these changes. This ensures that the data transformation steps (imputation, scaling, one-hot encoding) are applied correctly to all relevant features, including the new ones, before the model is trained.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24be46e0"
      },
      "outputs": [],
      "source": [
        "num_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\",\n",
        "     __import__(\"sklearn\").preprocessing.OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_features),\n",
        "    (\"cat\", cat_pipeline, cat_features)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f33c861"
      },
      "source": [
        "**Reasoning**:\n",
        "With the `preprocessor` updated to handle the new features, the model pipeline now needs to be re-assembled to incorporate this updated `preprocessor`. This ensures that the entire data processing and modeling workflow uses the most current feature set before model evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17c2e7d9"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    (\"prep\", preprocessor),\n",
        "    (\"model\", model)\n",
        "])\n",
        "\n",
        "print(\"Model pipeline re-assembled with updated preprocessor.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2db04b2"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the pipeline has been re-assembled with the updated preprocessor and new features, I need to re-evaluate the model's performance using cross-validation. This will allow us to assess if the advanced features have improved the model's predictive power.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "524c21e8"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmse = np.sqrt(-cross_val_score(\n",
        "    pipeline, train, y,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=kf\n",
        "))\n",
        "\n",
        "print(\"CV RMSE (after advanced features):\", rmse.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9652d710"
      },
      "source": [
        "## Implement Hyperparameter Tuning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2406465c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'model__n_estimators': [100, 300, 500],\n",
        "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'model__max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# Instantiate GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=kf,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    n_jobs=-1, # Use all available cores\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Starting GridSearchCV...\")\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(train, y)\n",
        "\n",
        "print(\"GridSearchCV completed.\")\n",
        "# Print the best parameters\n",
        "print(\"Best hyperparameters found:\", grid_search.best_params_)\n",
        "\n",
        "# Print the best cross-validation score (RMSE)\n",
        "best_rmse = np.sqrt(-grid_search.best_score_)\n",
        "print(\"Best CV RMSE:\", best_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d87c461"
      },
      "source": [
        "## Re-evaluate Model Performance\n",
        "\n",
        "### Subtask:\n",
        "Re-run the cross-validation step to measure the improved RMSE using the optimal hyperparameters found during GridSearchCV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c116d3b8"
      },
      "outputs": [],
      "source": [
        "best_pipeline = grid_search.best_estimator_\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmse_tuned = np.sqrt(-cross_val_score(\n",
        "    best_pipeline, train, y,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=kf\n",
        "))\n",
        "\n",
        "print(\"CV RMSE (after hyperparameter tuning):\", rmse_tuned.mean())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
